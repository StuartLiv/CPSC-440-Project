{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StuartLiv/CPSC-440-Project/blob/main/models/lab_statistics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from keras.preprocessing.image import img_to_array # TODO don't use keras\n",
        "from keras.utils import load_img\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "import torch.optim as optim\n",
        "import random\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "!pip install pytorch-msssim -q\n",
        "from pytorch_msssim import ms_ssim\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ],
      "metadata": {
        "id": "N-_96eljZSnh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d414f2-a076-4613-8e35-5c7a06be1580"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -q kornia\n",
        "import kornia\n",
        "import skimage\n",
        ""
      ],
      "metadata": {
        "id": "RuAD2u3RWbuG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Set up project in runtime\n",
        "Create colab secrets for the following credentials for the repo to get runtime files and clone repo"
      ],
      "metadata": {
        "id": "p2hPm3ge3aAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email {userdata.get('email')}\n",
        "!git config --global user.name {userdata.get('name')}\n",
        "!git clone https://{userdata.get('token')}@github.com/StuartLiv/CPSC-440-Project\n",
        "%pwd"
      ],
      "metadata": {
        "id": "uokAe0clHNCX",
        "outputId": "6ea07595-764d-4ce0-81fb-c499ab198890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CPSC-440-Project' already exists and is not an empty directory.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Preprocess data\n",
        "\n",
        "Datasets:\n",
        "- `medset_multisize`\n",
        "  - Single datasets. Dataset construction code in repo too\n",
        "  - 12000 Images, in randomized order\n",
        "  - Res 256x256 (grayscale images also available in 128x128, 64x64, 32x32)\n"
      ],
      "metadata": {
        "id": "y1rkmEoxY0bM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load datasets, partition sets, and make tensors in color-layer order for convolutions\n",
        "\n"
      ],
      "metadata": {
        "id": "klqfJGcYZnmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_image_arr(path,cut=None,end=False):\n",
        "\n",
        "  def sorted_alphanumeric(data):\n",
        "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
        "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n",
        "    return sorted(data,key = alphanum_key)\n",
        "\n",
        "  files = os.listdir(path)\n",
        "  files = sorted_alphanumeric(files)\n",
        "\n",
        "  if end:\n",
        "    files.reverse()\n",
        "  if cut is not None:\n",
        "    files = files[:cut]\n",
        "\n",
        "  arr = []\n",
        "  for i in tqdm(files):\n",
        "    img = load_img(path + '/'+i)\n",
        "    arr.append(img_to_array(img) / 255)\n",
        "\n",
        "  return np.array(arr)\n",
        "\n",
        "rgb_np = make_image_arr('/content/CPSC-440-Project/datasets/medset_multisize/color',cut=1200,end=True)\n",
        "lab_np = skimage.color.rgb2lab(rgb_np)\n",
        "color = torch.from_numpy(np.moveaxis(lab_np, [3,1], [1,2])).to(device)\n",
        "\n",
        "def make_gray_tensor(path):\n",
        "  graynp = make_image_arr('/content/CPSC-440-Project/datasets/medset_multisize/gray',cut=1200,end=True)\n",
        "\n",
        "  # take one axis\n",
        "  graynp = np.moveaxis(graynp, [3,1], [1,2])\n",
        "\n",
        "  # convert to LAB scale\n",
        "  graynp = graynp[:, 0:1, :, :] * 100\n",
        "\n",
        "  return torch.from_numpy(graynp).to(device)\n",
        "\n",
        "gray032 = make_gray_tensor('/content/CPSC-440-Project/datasets/medset_multisize/gray32')\n",
        "gray064 = make_gray_tensor('/content/CPSC-440-Project/datasets/medset_multisize/gray64')\n",
        "gray128 = make_gray_tensor('/content/CPSC-440-Project/datasets/medset_multisize/gray128')\n",
        "gray256 = make_gray_tensor('/content/CPSC-440-Project/datasets/medset_multisize/gray')\n"
      ],
      "metadata": {
        "id": "nbS2bT3vXKJc",
        "outputId": "d0fa31d8-d5b3-4baf-8d06-6995aaba083b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:01<00:00, 820.08it/s]\n",
            "100%|██████████| 1200/1200 [00:01<00:00, 872.17it/s]\n",
            "100%|██████████| 1200/1200 [00:01<00:00, 873.36it/s]\n",
            "100%|██████████| 1200/1200 [00:01<00:00, 880.44it/s]\n",
            "100%|██████████| 1200/1200 [00:01<00:00, 892.84it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(color.shape)\n",
        "print(gray032.shape)\n",
        "print(gray064.shape)\n",
        "print(gray128.shape)\n",
        "print(gray256.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJKHgs7bY1aZ",
        "outputId": "dbecfe80-70df-4b5d-bf8d-f128b088ab64"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1200, 3, 256, 256])\n",
            "torch.Size([1200, 1, 256, 256])\n",
            "torch.Size([1200, 1, 256, 256])\n",
            "torch.Size([1200, 1, 256, 256])\n",
            "torch.Size([1200, 1, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Model\n",
        "Model generated below:"
      ],
      "metadata": {
        "id": "WnA0Wvam63vM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kL2B0zg4cEoR"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self,intype):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # Encoder\n",
        "        if intype == 'gray032':\n",
        "          self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "          )\n",
        "        elif intype == 'gray064':\n",
        "          self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "        elif intype == 'gray128':\n",
        "          self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "        elif intype == 'gray256':\n",
        "          self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, 3, padding=1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 16, 3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "          )\n",
        "\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 16, 3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 3, 3, padding=1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "# Create the emergent superesolutions autoencoders\n",
        "esure032 = Autoencoder('gray032')\n",
        "esure064 = Autoencoder('gray064')\n",
        "esure128 = Autoencoder('gray128')\n",
        "esure256 = Autoencoder('gray256')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load stored decoder from full size model training, and fix decoder parameters."
      ],
      "metadata": {
        "id": "WGURKK2pVBRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "esure032.encoder = torch.load('/content/CPSC-440-Project/models/old models/lab_mle_encoder_32',map_location=device)\n",
        "esure064.encoder = torch.load('/content/CPSC-440-Project/models/old models/lab_mle_encoder_64',map_location=device)\n",
        "esure128.encoder = torch.load('/content/CPSC-440-Project/models/old models/lab_mle_encoder_128',map_location=device)\n",
        "esure256.encoder = torch.load('/content/CPSC-440-Project/models/old models/lab_mle_encoder',map_location=device)\n",
        "\n",
        "\n",
        "esures = [esure032,\n",
        "          esure064,\n",
        "          esure128,\n",
        "          esure256,\n",
        "          ]\n",
        "\n",
        "for esure in esures:\n",
        "  esure.decoder = torch.load('/content/CPSC-440-Project/models/old models/lab_mle_encoder',map_location=device)"
      ],
      "metadata": {
        "id": "FEfrbYp2VGDu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RGB evaluation"
      ],
      "metadata": {
        "id": "x0zt1_2TCWrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [gray032, gray064, gray128, gray256]\n",
        "dim_labels = [32,64,128,256]\n",
        "\n",
        "outputs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i in range(4):\n",
        "    esures[i].eval()\n",
        "    esures[i].to(device)\n",
        "    output = []\n",
        "\n",
        "    #Necessary due to GPU SIZE Restrictions on L4 (Maybe not A100?)\n",
        "    output.append(esures[i](inputs[i][:len(color)//4]).cpu())\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # output.append(esures[i](inputs[i][len(color)//2:]).cpu())\n",
        "    # outputs.append(torch.cat(output))\n",
        "    # torch.cuda.empty_cache()\n",
        "\n",
        "output = torch.stack(outputs)"
      ],
      "metadata": {
        "id": "OYwxUOmWAJjO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "17041d83-ae6e-4173-e5ef-e54ca0848107"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 18.75 GiB. GPU 0 has a total capacity of 22.17 GiB of which 1.12 GiB is free. Process 82192 has 21.04 GiB memory in use. Of the allocated memory 20.81 GiB is allocated by PyTorch, and 14.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b5c790988c84>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#Necessary due to GPU SIZE Restrictions on L4 (Maybe not A100?)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mesures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-b6d4de320746>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m         )\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2482\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m     )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 18.75 GiB. GPU 0 has a total capacity of 22.17 GiB of which 1.12 GiB is free. Process 82192 has 21.04 GiB memory in use. Of the allocated memory 20.81 GiB is allocated by PyTorch, and 14.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "GPgGcn9PbKki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.color import rgb2lab, lab2rgb\n",
        "\n",
        "def to_lab_tensor(input):\n",
        "  arr = []\n",
        "  for i in range(input.shape[0]):\n",
        "    arr.append(rgb2lab(input[i].detach().numpy(), channel_axis=0))\n",
        "  return torch.from_numpy(np.array(arr))"
      ],
      "metadata": {
        "id": "CGpHttaWztng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_diffs = []\n",
        "for i in range(4):\n",
        "  color_diffs.append(ms_ssim(to_lab_tensor(output[i]), to_lab_tensor(color), data_range = 1, size_average=False))\n",
        "\n",
        "color_diffs = torch.stack(color_diffs)"
      ],
      "metadata": {
        "id": "ZR03jZnmM7Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.boxplot(np.transpose(color_diffs.numpy()),\n",
        "            labels = dim_labels)\n",
        "            #xlabel = \"MSSIM Score\",\n",
        "            #ylabel = \"Input Resolution\")\n",
        "plt.ylabel(\"MSSIM Score\")\n",
        "plt.xlabel(\"Input Resolution\")\n",
        "plt.title(\"Test Set MMSIM Score by Input Resolution (LAB)\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uzu-f39ZP6vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_input_diffs = []\n",
        "\n",
        "for i in range(4):\n",
        "  upscaled = f.interpolate(inputs[i].reshape(len(color),1,dim_labels[i],dim_labels[i]),size=[256,256]).repeat(1, 3, 1, 1)\n",
        "  color_input_diffs.append(ms_ssim(to_lab_tensor(upscaled), to_lab_tensor(color), data_range = 1, size_average=False))\n",
        "\n",
        "color_input_diffs = torch.stack(color_input_diffs)"
      ],
      "metadata": {
        "id": "zsikWrxDumdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recovery_factor = torch.div(color_diffs, color_input_diffs)\n",
        "\n",
        "plt.boxplot(np.transpose(recovery_factor.numpy()),\n",
        "            labels = dim_labels)\n",
        "            #xlabel = \"MSSIM Score\",\n",
        "            #ylabel = \"Input Resolution\")\n",
        "plt.ylabel(\"Recovery Factor\")\n",
        "plt.xlabel(\"Input Resolution\")\n",
        "plt.title(\"Recovery Factor Score by Input Resolution (LAB)\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q9wo-BixvYPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim_labels = [32,64,128,256]\n",
        "bw_input_diffs = []\n",
        "\n",
        "#In theory b/w images unaffected by switch to LAB?\n",
        "\n",
        "for i in range(4):\n",
        "  upscaled = f.interpolate(inputs[i].reshape(len(color),1,dim_labels[i],dim_labels[i]),size=[256,256])\n",
        "  bw_input_diffs.append(ms_ssim(upscaled, gray256, data_range = 1, size_average=False))\n",
        "\n",
        "bw_input_diffs = torch.stack(bw_input_diffs)\n",
        "\n",
        "bw_output_diffs = []\n",
        "\n",
        "for i in range(4):\n",
        "  bw_outputs = torch.mean(outputs[i], dim=1, keepdim=True)\n",
        "  bw_output_diffs.append(ms_ssim(bw_outputs, gray256, data_range = 1, size_average=False))\n",
        "\n",
        "bw_output_diffs = torch.stack(bw_output_diffs)\n"
      ],
      "metadata": {
        "id": "a5Hu9M1bP6es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.boxplot(np.transpose(bw_output_diffs.numpy()),\n",
        "            labels = dim_labels)\n",
        "            #xlabel = \"MSSIM Score\",\n",
        "            #ylabel = \"Input Resolution\")\n",
        "plt.ylabel(\"MSSIM Score\")\n",
        "plt.xlabel(\"Input Resolution\")\n",
        "plt.title(\"Grayscale MMSIM Score by Input Resolution (RGB)\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fYGanhypoB3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bw_recovery_factor = torch.div(bw_output_diffs, bw_input_diffs)\n",
        "\n",
        "plt.boxplot(np.transpose(bw_recovery_factor.numpy()),\n",
        "            labels = dim_labels)\n",
        "            #xlabel = \"MSSIM Score\",\n",
        "            #ylabel = \"Input Resolution\")\n",
        "plt.ylabel(\"Recovery Factor\")\n",
        "plt.xlabel(\"Input Resolution\")\n",
        "plt.title(\"Grayscale Recovery Factor Score by Input Resolution (RGB)\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Co1HolS7lqnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bw_sub_color = torch.sub(bw_output_diffs, color_diffs)\n",
        "\n",
        "plt.boxplot(np.transpose(bw_sub_color.numpy()),\n",
        "            labels = dim_labels)\n",
        "            #xlabel = \"MSSIM Score\",\n",
        "            #ylabel = \"Input Resolution\")\n",
        "plt.ylabel(\"MSSIM Difference\")\n",
        "plt.xlabel(\"Input Resolution\")\n",
        "plt.title(\"Test Set BW MSSIM Score minus Color score (RGB)\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K83FexahqEkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recovery_factor = torch.div(color_diffs, bw_input_diffs)\n",
        "\n",
        "plt.boxplot(np.transpose(bw_recovery_factor.numpy()),\n",
        "            labels = dim_labels)\n",
        "            #xlabel = \"MSSIM Score\",\n",
        "            #ylabel = \"Input Resolution\")\n",
        "plt.ylabel(\"Recovery Factor\")\n",
        "plt.xlabel(\"Input Resolution\")\n",
        "plt.title(\"Grayscale Recovery Factor Score by Input Resolution (RGB)\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hnc216-vuXEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_qaURhda6yW9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}